{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLO + SAM2 Object Segmentation\n",
    "\n",
    "**Author**: Michal Balogh\n",
    "\n",
    "This notebook demonstrates a combined approach for object segmentation using:\n",
    "1. **YOLO** (You Only Look Once) for object detection\n",
    "2. **SAM2** (Segment Anything Model 2) for precise segmentation\n",
    "\n",
    "The workflow involves detecting objects with YOLO to get bounding boxes, then using these boxes with SAM2 to generate high-quality segmentation masks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO, SAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('results', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train YOLO Model\n",
    "\n",
    "In this section, we train a YOLO model on a custom dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO model loaded on cpu\n"
     ]
    }
   ],
   "source": [
    "yolo_model = YOLO(\"yolo11n.pt\")\n",
    "yolo_model.to(device)\n",
    "print(f\"YOLO model loaded on {yolo_model.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "# Uncomment to run training\n",
    "# results = yolo_model.train(data=\"mei_dataset.yaml\", epochs=10, imgsz=640)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Object Detection with YOLO\n",
    "\n",
    "Load the trained model and run object detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from runs/detect/train/weights/best.pt\n"
     ]
    }
   ],
   "source": [
    "# Load the best model from training\n",
    "run = \"train\"\n",
    "model_path = f\"runs/detect/{run}/weights/best.pt\"\n",
    "\n",
    "# Or get the latest model from the runs directory:\n",
    "# all_runs = os.listdir(\"runs/detect\")\n",
    "# run = sorted(all_runs)[-1]\n",
    "# model_path = f\"runs/detect/{run}/weights/best.pt\"\n",
    "\n",
    "yolo_model = YOLO(model_path)\n",
    "print(f\"Loaded model from {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 c:\\Users\\balog\\Code_win\\Code\\BP\\yolo-sam2\\heightMap.png: 288x640 1 /, 2 5s, 2 As, 1 D, 1 E, 1 I, 2 Ls, 3 Rs, 1 T, 1 U, 78.2ms\n",
      "Speed: 1.9ms preprocess, 78.2ms inference, 1.2ms postprocess per image at shape (1, 3, 288, 640)\n"
     ]
    }
   ],
   "source": [
    "img_path = \"heightMap.png\"\n",
    "\n",
    "results = yolo_model(img_path, conf=0.5)\n",
    "results[0].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected 15 objects:\n",
      "Class IDs:  [19, 13, 13, 19, 23, 38, 36, 30, 7, 36, 36, 30, 39, 22, 27]\n",
      "Boxes:  [[1264, 498, 1405, 610], [207, 714, 503, 879], [1359, 705, 1657, 875], [802, 499, 940, 611], [2220, 487, 2347, 601], [1725, 493, 1818, 604], [2122, 699, 2439, 870], [1453, 496, 1552, 609], [592, 698, 889, 890], [629, 501, 756, 614], [2202, 736, 2356, 791], [2393, 487, 2499, 601], [1870, 493, 1997, 603], [991, 497, 1116, 611], [1177, 496, 1207, 609]]\n",
      "Confidence scores:  ['0.995', '0.993', '0.992', '0.992', '0.986', '0.958', '0.956', '0.943', '0.937', '0.933', '0.924', '0.897', '0.815', '0.797', '0.572']\n"
     ]
    }
   ],
   "source": [
    "# Analyze detection results\n",
    "class_ids = results[0].boxes.cls.int().tolist()\n",
    "boxes = results[0].boxes.xyxy.int().tolist()\n",
    "scores = results[0].boxes.conf.tolist()\n",
    "\n",
    "print(f\"Detected {len(class_ids)} objects:\")\n",
    "print(\"Class IDs: \", class_ids)\n",
    "print(\"Boxes: \", boxes)\n",
    "print(\"Confidence scores: \", [f\"{score:.3f}\" for score in scores])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Object Segmentation with SAM2\n",
    "\n",
    "Use SAM2 model to generate segmentation masks based on YOLO's bounding boxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running YOLO detection with confidence threshold 0.3...\n",
      "\n",
      "image 1/1 c:\\Users\\balog\\Code_win\\Code\\BP\\yolo-sam2\\heightMap.png: 288x640 1 /, 2 5s, 2 As, 2 Ds, 1 E, 1 I, 2 Ls, 3 Rs, 1 T, 1 U, 63.3ms\n",
      "Speed: 1.4ms preprocess, 63.3ms inference, 1.0ms postprocess per image at shape (1, 3, 288, 640)\n",
      "Loading SAM2 model from sam2_b.pt...\n",
      "Found 16 bounding boxes for segmentation\n"
     ]
    }
   ],
   "source": [
    "img_path = \"heightMap.png\"\n",
    "conf_threshold = 0.3\n",
    "\n",
    "# Get bounding boxes from YOLO detection\n",
    "print(f\"Running YOLO detection with confidence threshold {conf_threshold}...\")\n",
    "yolo_output = yolo_model(img_path, conf=conf_threshold)[0]\n",
    "\n",
    "# Load SAM model\n",
    "sam_ckpt = \"sam2_b.pt\"\n",
    "print(f\"Loading SAM2 model from {sam_ckpt}...\")\n",
    "sam_model = SAM(sam_ckpt)\n",
    "\n",
    "# Extract bounding boxes from YOLO detection\n",
    "boxes = yolo_output.boxes.xyxy \n",
    "print(f\"Found {len(boxes)} bounding boxes for segmentation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running SAM2 segmentation on cpu...\n",
      "Results saved to \u001b[1mruns\\segment\\predict6\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'results/segmentation_heightMap.png'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run SAM2 segmentation\n",
    "print(f\"Running SAM2 segmentation on {device}...\")\n",
    "sam_output = sam_model(\n",
    "    yolo_output.orig_img, \n",
    "    bboxes=boxes, \n",
    "    verbose=False, \n",
    "    device=device, \n",
    "    save=True\n",
    ")[0]\n",
    "\n",
    "# Save segmentation results\n",
    "sam_output.save(filename=f\"results/segmentation_{Path(img_path).name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected class IDs: [19, 13, 13, 19, 23, 38, 36, 30, 7, 36, 36, 30, 39, 22, 27, 22]\n",
      "Class mapping: {0: 'tick', 1: '(', 2: ')', 3: 'asterisk', 4: '+', 5: '_', 6: '.', 7: '/', 8: '0', 9: '1', 10: '2', 11: '3', 12: '4', 13: '5', 14: '6', 15: '7', 16: '8', 17: '9', 18: 'colon', 19: 'A', 20: 'B', 21: 'C', 22: 'D', 23: 'E', 24: 'F', 25: 'G', 26: 'H', 27: 'I', 28: 'J', 29: 'K', 30: 'L', 31: 'M', 32: 'N', 33: 'O', 34: 'P', 35: 'Q', 36: 'R', 37: 'S', 38: 'T', 39: 'U', 40: 'V', 41: 'W', 42: 'X', 43: 'Y', 44: 'Z', 45: 'a', 46: 'b', 47: 'd', 48: 'e', 49: 'g', 50: 'i', 51: 'k', 52: 'l', 53: 'n', 54: 'o', 55: 'p', 56: 'r', 57: 's', 58: 't', 59: 'u', 60: 'speical_symbol_127', 61: 'speical_symbol_128', 62: 'speical_symbol_129', 63: 'speical_symbol_131', 64: 'speical_symbol_132', 65: 'speical_symbol_133', 66: 'speical_symbol_134', 67: 'speical_symbol_135', 68: 'speical_symbol_136', 69: 'speical_symbol_137', 70: 'speical_symbol_138'}\n",
      "\n",
      "Segmentation masks with class names:\n",
      "{0: 'A', 1: '5', 2: '5', 3: 'A', 4: 'E', 5: 'T', 6: 'R', 7: 'L', 8: '/', 9: 'R', 10: 'R', 11: 'L', 12: 'U', 13: 'D', 14: 'I', 15: 'D'}\n"
     ]
    }
   ],
   "source": [
    "# Map class IDs to class names\n",
    "id2label = yolo_output.names\n",
    "class_ids = yolo_output.boxes.cls.int().tolist()\n",
    "\n",
    "print(\"Detected class IDs:\", class_ids)\n",
    "print(\"Class mapping:\", id2label)\n",
    "\n",
    "# Assign class names to segmentation masks\n",
    "sam_output_ids = {i: class_id for i, class_id in enumerate(class_ids)}\n",
    "sam_output.names = {k: id2label[int(v)] for k,v in sam_output_ids.items()}\n",
    "print(\"\\nSegmentation masks with class names:\")\n",
    "print(sam_output.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam_output.show(labels=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo-sam2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
